{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_path = \"/mnt/cloudNAS3/Adubois/Classes/ECE661/HW6/Output_Images/Contour_Extraction/\"\n",
    "rgb_path = \"/mnt/cloudNAS3/Adubois/Classes/ECE661/HW6/Output_Images/RGB_Otsus/\"\n",
    "texture_path = \"/mnt/cloudNAS3/Adubois/Classes/ECE661/HW6/Output_Images/Texture_Segmentation/\"\n",
    "histogram_paths = \"/mnt/cloudNAS3/Adubois/Classes/ECE661/HW6/Histograms/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split images into RBG:\n",
    "def get_bgr_split_images(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    return cv2.split(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image Object:\n",
    "def display_img_object(img, isOpenCV=True):\n",
    "    if isOpenCV:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBG Segmentation\n",
    "def get_Otsus_segmentation(img_channel, img_name, iter, subfolder):\n",
    "    num_bins = int(np.max(img_channel) - np.min(img_channel) + 1)\n",
    "    hist, bin_edges = np.histogram(img_channel, bins=num_bins)\n",
    "    \n",
    "    # Get histogram probabilities\n",
    "    p_i = hist / sum(hist)\n",
    "    \n",
    "    # List to save between class variances\n",
    "    variances = np.zeros((len(bin_edges)))\n",
    "    \n",
    "    # Go through all threshold ts and find the one that maximizes the fisher discriminant\n",
    "    # I only work with the pixels left from the previous iteration of Otsu's algorithm.\n",
    "    # So, my loop for the t values can only get larger than the previous one\n",
    "    for t in range(len(bin_edges)):\n",
    "        # Probability of picking points from each class = sum(p(i))\n",
    "        w0 = np.sum(p_i[:t])\n",
    "        w1 = np.sum(p_i[t:])\n",
    "        \n",
    "        if w0 == 0 or w1 == 0:\n",
    "            continue\n",
    "        \n",
    "        # Mean levels for each class = sum(i * p(i))\n",
    "        i = np.arange(len(p_i))\n",
    "        mu0 = np.sum(i[:t] * p_i[:t])/w0\n",
    "        mu1 = np.sum(i[t:] * p_i[t:])/w1\n",
    "        \n",
    "        # Between class varianced\n",
    "        omegaB = w0 * w1 * (mu1 - mu0)**2\n",
    "        \n",
    "        # Append fisher's discriminant to the variances list\n",
    "        variances[t] = omegaB\n",
    "        \n",
    "    optimal_threshold = np.argmax(variances)\n",
    "        \n",
    "    # Save a graph of the histogram with the variances at each t plotted on top\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges), edgecolor=\"black\", align=\"edge\", label=\"Pixel Value Histogram\")\n",
    "    plt.plot(variances, color='r', label=\"Between class variances at each t\")\n",
    "    plt.axvline(x=optimal_threshold, color=\"k\", linestyle=\"--\", linewidth=2, label=\"Optimal Threshold\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(histogram_paths + subfolder + img_name + \"_hist_\" + str(iter) + \".jpg\", format=\"jpg\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Return the t that maximized fisher's ratio\n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texture Segmentation\n",
    "def get_texture_ostu(grey_img, N):\n",
    "    # Create canvas for output image\n",
    "    output_channel = np.zeros_like(grey_img)\n",
    "    \n",
    "    # Pad the image with extra 0s as necessary\n",
    "    padded_img = np.pad(grey_img, pad_width=N, mode=\"constant\", constant_values=0)\n",
    "    \n",
    "    # Create an N by N window of the nearby pixels with 0 padding\n",
    "    # Instead of using a double for loop which is slow, I do this through numpy vectorized functions\n",
    "    # This will return a numpy array of shape: (H, W, 2N + 1, 2N + 1) (list of windows)\n",
    "    # We do 2N + 1 since we want N on each direction from the input pixel\n",
    "    window_shape = (2*N + 1, 2*N + 1)\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(padded_img, window_shape)\n",
    "    \n",
    "    # Substract the window's mean value\n",
    "    window_means = np.mean(windows, axis=(-2, -1))\n",
    "    windows = windows - window_means[:,:, None, None]\n",
    "    \n",
    "    # Compute the variance within each window\n",
    "    window_variances = np.var(windows, axis=(-2, -1))\n",
    "    \n",
    "    # Normalize the variance to 0-1 range and scale to 255 for BW image\n",
    "    output_channel = (window_variances - window_variances.min()) / (window_variances.max() - window_variances.min()) * 255\n",
    "\n",
    "    # Return a new array with the within pixel variance as the center pixel value\n",
    "    # These values are normalized to 0-255\n",
    "    return output_channel.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(img):\n",
    "    window_shape = (3,3)\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(img, window_shape)\n",
    "    \n",
    "    # We only want to look at windows where the center pixel is 1:\n",
    "    center_pixels = windows[:, :, 1, 1]\n",
    "    center_pixel_mask = center_pixels == 1\n",
    "    \n",
    "    # Create a mask that will look in each window and check for a 0 pixel\n",
    "    # If there is a 0, it will return a 1, otherwise return a 0\n",
    "    zero_mask = np.any(windows == 0, axis=(2, 3)).astype(int)\n",
    "    \n",
    "    final_mask = np.logical_and(center_pixel_mask, zero_mask)\n",
    "\n",
    "    # Convert to grey scale (0->255)\n",
    "    return final_mask * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_opening(contour, kernel_size):\n",
    "    # Opening is erosion followed by dillation\n",
    "    # Here we define the kernel for the area we want to run these algorithms on\n",
    "    kernel = np.ones((kernel_size, kernel_size), dtype=np.uint8)\n",
    "    \n",
    "    # First we run erosion on the contour\n",
    "    contour = cv2.erode(contour.astype(np.float32), kernel, iterations=1)\n",
    "    \n",
    "    # Then we run dillation:\n",
    "    contour = cv2.dilate(contour.astype(np.float32), kernel, iterations=2) \n",
    "    return contour\n",
    "    \n",
    "def run_closing(contour, kernel_size):\n",
    "    # Closing is dillation followed by erosion\n",
    "    kernel = np.ones((kernel_size, kernel_size), dtype=np.uint8)\n",
    "\n",
    "    contour = cv2.dilate(contour.astype(np.float32), kernel, iterations=3)\n",
    "    contour = cv2.erode(contour.astype(np.float32), kernel, iterations=1)\n",
    "    return contour\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Otsus_algorithm_iterative(iters, save_path, invert, img_path=None, img=None, img_name=\"\", histogram_folder=\"\"):\n",
    "    \"\"\"\n",
    "        Runs an iterative version of Otsus algorithm. Will print the following results:\n",
    "            - Seperate masks for each channel dimension  \n",
    "            - A joined mask highlighting the RGB extractions for each mask  \n",
    "            - The histogram with variance values at each tested threshold for Otsu's algorithm.  \n",
    "\n",
    "    Args:\n",
    "        iters (int): number of iters to run Otsus\n",
    "        save_path (string): path pointing to where you want the images to be saved\n",
    "        img_path (string, optional): Path to the image. Defaults to None.\n",
    "        img (OpenCV Image Object, optional): OpenCV BGR Image. Defaults to None.\n",
    "        img_name (str, optional): NameID for image printouts. Defaults to \"\".\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Working on the following image:\", img_name)\n",
    "    if img_path != None:\n",
    "        channels = get_bgr_split_images(img_path)\n",
    "    else:\n",
    "        channels = cv2.split(img)\n",
    "    \n",
    "    final_rgb_img = np.zeros((channels[0].shape[0], channels[0].shape[1], 3), dtype=np.uint8)\n",
    "    final_mask = np.ones_like(channels[0], dtype=np.uint8)\n",
    "    \n",
    "    for i, channel in enumerate(channels):\n",
    "        flattened_channel = channel.flatten()\n",
    "        # Channel I am working on:\n",
    "        channel_name = [\"_blue\", \"_green\", \"_red\"][i]\n",
    "        print(\"Working on the following channel: \", channel_name)\n",
    "        \n",
    "        for iter in range(iters[i]):\n",
    "            # As I run Otsu's algorithm, more of my pixels become 0 due to the masking.\n",
    "            optimal_threshold = get_Otsus_segmentation(flattened_channel, img_name, iter, histogram_folder)\n",
    "            \n",
    "            # Print the optimal threshold:\n",
    "            print(\"Optimal Threshold: \", optimal_threshold)\n",
    "            \n",
    "            # If the values in the channel are lessthan the threshold -> replace it with 0 in the bw_img or do the opposite.\n",
    "            # This choice can be made depending on whether the foreground is a bright object, or a dark one.\n",
    "            # If foreground is closer to white, you want to keep Class 1 (brighter pixels), else keep class 0 (darker pixels)\n",
    "            if not invert:\n",
    "                bw_img = np.zeros(channel.shape, dtype=np.uint8)\n",
    "                bw_img[channel<optimal_threshold] = 255\n",
    "            else:\n",
    "                bw_img = np.ones_like(channel) * 255\n",
    "                bw_img[channel<optimal_threshold] = 0\n",
    "            \n",
    "            # Fill in the channels for the final image:\n",
    "            final_rgb_img[:, :, i] = bw_img\n",
    "            \n",
    "            # Save the masked image to a file\n",
    "            cv2.imwrite(save_path + \"RGB_Seperate/Iter\" + str(iter) + \"/\" + img_name + channel_name + \".jpg\", bw_img)\n",
    "            \n",
    "            # Update channel to new image for next iteration:\n",
    "            # Use the bw_img as a mask on top of the old channel\n",
    "            # channel = channel * (bw_img // 255)\n",
    "            flattened_channel = flattened_channel[flattened_channel < optimal_threshold]\n",
    "        \n",
    "        \n",
    "        # Final mask is a logical and of the masks from all of the final masks after all iterations of thresholding\n",
    "        final_mask = np.logical_and(bw_img // 255, final_mask).astype(np.uint8)\n",
    "            \n",
    "    # Save the image with the combined masks:\n",
    "    final_mask_img = final_mask * 255\n",
    "    cv2.imwrite(save_path + \"Final_Images/\" + img_name + \".jpg\", final_mask_img)\n",
    "    \n",
    "    # Save the final image in RBG with all channels masked seperately:\n",
    "    cv2.imwrite(save_path + \"RGB_Final_Masks/\" + img_name + \".jpg\", final_rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/mnt/cloudNAS3/Adubois/Classes/ECE661/HW6/pics/\"\n",
    "img_paths = [input_folder+img_name for img_name in os.listdir(input_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on the following image: climg\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  103\n",
      "Optimal Threshold:  64\n",
      "Optimal Threshold:  37\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  122\n",
      "Optimal Threshold:  77\n",
      "Optimal Threshold:  49\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  134\n",
      "Optimal Threshold:  86\n",
      "Optimal Threshold:  62\n",
      "Optimal Threshold:  40\n",
      "Working on the following image: flower_small\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  126\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  136\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  140\n",
      "Working on the following image: dog_small\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  84\n",
      "Optimal Threshold:  39\n",
      "Optimal Threshold:  17\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  132\n",
      "Optimal Threshold:  68\n",
      "Optimal Threshold:  29\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  120\n",
      "Optimal Threshold:  57\n",
      "Optimal Threshold:  24\n",
      "Working on the following image: rvl\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  112\n",
      "Optimal Threshold:  56\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  137\n",
      "Optimal Threshold:  70\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  135\n",
      "Optimal Threshold:  56\n"
     ]
    }
   ],
   "source": [
    "# Otsu's Algorithm for RGB images:\n",
    "# Images are in the following order: Climb, Flower, dog_small, RVL\n",
    "iters = [[3,3,4], \n",
    "         [1,1,1],\n",
    "         [3,3,3],\n",
    "         [2,2,2]]\n",
    "invert = [False, True, False, False]\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    img_name = img_path.split(\"/\")[-1][:-4]\n",
    "    run_Otsus_algorithm_iterative(iters=iters[i], save_path=rgb_path, invert=invert[i], img_path=img_path, img=None, img_name=img_name, histogram_folder=\"RGB/\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on the following image: climg\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  30\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  32\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  33\n",
      "Working on the following image: flower_small\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  31\n",
      "Optimal Threshold:  9\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  31\n",
      "Optimal Threshold:  9\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  32\n",
      "Optimal Threshold:  10\n",
      "Working on the following image: dog_small\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  34\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  33\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  32\n",
      "Working on the following image: rvl\n",
      "Working on the following channel:  _blue\n",
      "Optimal Threshold:  51\n",
      "Optimal Threshold:  14\n",
      "Optimal Threshold:  4\n",
      "Working on the following channel:  _green\n",
      "Optimal Threshold:  46\n",
      "Optimal Threshold:  14\n",
      "Working on the following channel:  _red\n",
      "Optimal Threshold:  44\n",
      "Optimal Threshold:  14\n"
     ]
    }
   ],
   "source": [
    "# Images are in the following order: Climb, Flower, dog_small, RVL\n",
    "iters = [[1,1,1],\n",
    "         [2,2,2],\n",
    "         [1,1,1],\n",
    "         [3,2,2]]\n",
    "invert = [True, True, True, True]\n",
    "window_sizes = [[3, 5, 7],\n",
    "                [3, 5, 7],\n",
    "                [5, 4, 3],\n",
    "                [1, 2, 3]]\n",
    "\n",
    "# Otsu's algorithm based on texture:\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    img_name = img_path.split(\"/\")[-1][:-4]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    final_mask = np.ones_like(img, dtype=np.uint8)\n",
    "    \n",
    "    # Initialize image to fill in with texture data\n",
    "    new_img = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "    \n",
    "    for channel_idx ,N in enumerate(window_sizes[i]):\n",
    "        # Run Texture Otsu on the image:\n",
    "        channel = get_texture_ostu(img, N)\n",
    "\n",
    "        # Input the texture Otsu outputs as channels for BGR Otsu\n",
    "        new_img[:,:,channel_idx] = channel\n",
    "    # I now have a new image that I need to segment using BGR Otsu's Algorithm\n",
    "    run_Otsus_algorithm_iterative(iters=iters[i], save_path=texture_path, invert=invert[i], img_path=None, img=new_img, img_name=img_name, histogram_folder=\"Texture/\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image_dirs = [\"/mnt/cloudNAS3/Adubois/Classes/ECE661/HW6/Output_Images/Texture_Segmentation/Final_Images/\",\n",
    "                   \"/mnt/cloudNAS3/Adubois/Classes/ECE661/HW6/Output_Images/RGB_Otsus/Final_Images/\"]\n",
    "types = [\"texture\", \"rgb\"]\n",
    "for type, final_img_dir in zip(types, final_image_dirs):\n",
    "    for img_name in os.listdir(final_img_dir):\n",
    "        # Run the contouring on that image\n",
    "        \n",
    "        # Open the image:\n",
    "        img = cv2.imread(final_img_dir + img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Get the image contour:\n",
    "        contour = get_contours(img)\n",
    "        \n",
    "        # Save the images:\n",
    "        cv2.imwrite(contour_path+img_name[:-4] + \"_\" + type + \".jpg\", contour)\n",
    "        \n",
    "        # Run Closing on the images:\n",
    "        closed_contour = run_closing(contour, 3)\n",
    "        cv2.imwrite(contour_path+\"Post_Closing/\" + img_name[:-4] + \"_\" + type + \".jpg\", closed_contour)\n",
    "        \n",
    "        # Run Opening on the images:\n",
    "        opened_contour = run_opening(contour, 3)\n",
    "        cv2.imwrite(contour_path+\"Post_Opening/\" + img_name[:-4] + \"_\" + type + \".jpg\", closed_contour)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece661",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
